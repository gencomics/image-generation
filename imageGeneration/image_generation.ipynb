{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqsTRGZXNC72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWFMu61gOooC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try:\n",
        "#   %tensorflow_version 2.x\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER3cOVNuPLcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zfmo1G9PRZx",
        "colab_type": "code",
        "outputId": "cf4116d9-4762-4327-e2f4-7be49aaa2919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHNoYmYKPVSb",
        "colab_type": "code",
        "outputId": "8262ca95-5069-4845-fec1-98c421866aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#To generate gifs\n",
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0NxgXcAPc8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJcIs91gI3jC",
        "colab_type": "code",
        "outputId": "abd4ac25-721f-471d-be15-35dc47058557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQv3a66JEEi",
        "colab_type": "code",
        "outputId": "c0b91882-d613-4824-e414-c848411ff333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/garfield\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ga190201.gif  ga190403.gif  ga190804.jpg  ga190903.gif\tga191203.gif\n",
            "ga190202.gif  ga190404.gif  ga190805.gif  ga190904.gif\tga191204.gif\n",
            "ga190203.jpg  ga190405.gif  ga190806.gif  ga190905.gif\tga191205.gif\n",
            "ga190204.gif  ga190406.gif  ga190807.gif  ga190906.gif\tga191206.gif\n",
            "ga190205.gif  ga190407.jpg  ga190808.gif  ga190907.gif\tga191207.gif\n",
            "ga190206.gif  ga190408.gif  ga190809.gif  ga190908.jpg\tga191208.jpg\n",
            "ga190207.gif  ga190409.gif  ga190810.gif  ga190909.gif\tga191209.gif\n",
            "ga190208.gif  ga190411.gif  ga190811.jpg  ga190910.gif\tga191210.gif\n",
            "ga190209.gif  ga190412.gif  ga190812.gif  ga190911.gif\tga191211.gif\n",
            "ga190210.jpg  ga190413.gif  ga190813.gif  ga190912.gif\tga191212.gif\n",
            "ga190211.gif  ga190414.jpg  ga190814.gif  ga190913.gif\tga191213.gif\n",
            "ga190212.gif  ga190415.gif  ga190815.gif  ga190914.gif\tga191214.gif\n",
            "ga190213.gif  ga190416.gif  ga190816.gif  ga190915.jpg\tga191215.jpg\n",
            "ga190214.gif  ga190417.gif  ga190817.gif  ga190916.gif\tga191216.gif\n",
            "ga190215.gif  ga190418.gif  ga190818.jpg  ga190917.gif\tga191217.gif\n",
            "ga190216.gif  ga190419.gif  ga190819.gif  ga190918.gif\tga191218.gif\n",
            "ga190217.jpg  ga190420.gif  ga190820.gif  ga190919.gif\tga191219.gif\n",
            "ga190218.gif  ga190421.jpg  ga190821.gif  ga190920.gif\tga191220.gif\n",
            "ga190219.gif  ga190422.gif  ga190822.gif  ga190921.gif\tga191221.gif\n",
            "ga190220.gif  ga190423.gif  ga190823.gif  ga190922.jpg\tga191222.jpg\n",
            "ga190221.gif  ga190424.gif  ga190824.gif  ga190923.gif\tga191223.gif\n",
            "ga190222.gif  ga190425.gif  ga190825.jpg  ga190924.gif\tga191224.gif\n",
            "ga190223.gif  ga190426.gif  ga190826.gif  ga190925.gif\tga191225.gif\n",
            "ga190224.jpg  ga190427.gif  ga190827.gif  ga190926.gif\tga191226.gif\n",
            "ga190225.gif  ga190428.jpg  ga190828.gif  ga190927.gif\tga191227.gif\n",
            "ga190226.gif  ga190429.gif  ga190829.gif  ga190928.gif\tga191228.gif\n",
            "ga190227.gif  ga190430.gif  ga190830.gif  ga190929.jpg\tga191229.jpg\n",
            "ga190228.gif  ga190801.gif  ga190831.gif  ga190930.gif\tga191230.gif\n",
            "ga190401.gif  ga190802.gif  ga190901.jpg  ga191201.jpg\tga191231.gif\n",
            "ga190402.gif  ga190803.gif  ga190902.gif  ga191202.gif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXhX7709QPL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import savez_compressed\n",
        "import os\n",
        "from PIL import Image \n",
        " \n",
        "# load all images in a directory into memory\n",
        "def load_images(path, size=(256,768)):\n",
        "  src_list, tar_list,image3_list = list(), list(),list()\n",
        "  for filename in listdir(path):\n",
        "    if os.path.isfile(path +filename) and not filename.startswith('.'):\n",
        "      # Converting image to black and white\n",
        "      # image_file = Image.open(path+filename) # open colour image\n",
        "      # image_file = image_file.convert('1') # convert image to black and white\n",
        "      # image_file.save(path+filename)\n",
        "      pixels = load_img(path + filename, target_size=size)\n",
        "      pixels = img_to_array(pixels)\n",
        "      print(\"-------------------------------Image--------------------------------------\")\n",
        "      print(pixels)\n",
        "      print(pixels.shape)\n",
        "      pixels = pixels.mean(axis = 2)\n",
        "      print(\"After taking the axis \")\n",
        "      print(pixels.shape)\n",
        "      sat_img, map_img,image3 = pixels[:, :256], pixels[:, 256:512], pixels[:,512:]\n",
        "      src_list.append(sat_img)\n",
        "      tar_list.append(map_img)\n",
        "      src_list.append(image3)\n",
        "  return [asarray(src_list), asarray(tar_list)]\n",
        " \n",
        "# dataset path\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/garfield/\"\n",
        "# load dataset\n",
        "[src_images, tar_images] = load_images(path)\n",
        "print('SRC images : {}'.format(src_images))\n",
        "# print('TAR images : {}'.format(tar_images))\n",
        "# print('Loaded: ', src_images.shape, tar_images.shape)\n",
        "# save as compressed numpy array\n",
        "# filename = 'maps_256.npz'\n",
        "# savez_compressed(filename, src_images, tar_images)\n",
        "# print('Saved dataset: ', filename)\n",
        "train_images = src_images\n",
        "#(train_images,train_labels),(_,_)= tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(src_images[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3H5KrG2SNwR",
        "colab_type": "code",
        "outputId": "feff07ea-185f-45ca-ed4f-20720bbdcb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(298, 256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-sMTw0XRTWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0],256,256,1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IT3goOVR5O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = (train_images - 127.5)/127.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aha8O78_SUGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ty7_ORSU9yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 6000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaqtFtv8V-AR",
        "colab_type": "code",
        "outputId": "fb2adffa-d2db-43d6-ff29-2e88e80270b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (?, 256, 256, 3), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zfxDNl_bZ8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(64*64*256, use_bias=False, input_shape=(100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Reshape((64, 64, 256)))\n",
        "  assert model.output_shape == (None, 64, 64, 256) # Note: None is the batch size\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 64, 64, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 128, 128, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(3, (5, 5), strides=(3, 3), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 256, 256, 3)\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213huGUGpE1z",
        "colab_type": "code",
        "outputId": "5a4c692f-68c8-4851-a8e5-c8a8fd94866b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "generator = make_generator_model()\n",
        "print(type(generator))\n",
        "noise = tf.random.normal([1, 100])\n",
        "print(noise.shape)\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-1d367691c30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_generator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-831e266a705d>\u001b[0m in \u001b[0;36mmake_generator_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIqyyU_o3tbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[256, 256,3]))\n",
        "\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128,(5,5), strides=(2,2),padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCtZZfhEYA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = make_discriminator()\n",
        "\n",
        "decision = discriminator(generated_image)\n",
        "print(decision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQrN-m7VGHry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6B7rWp5J2G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Discriminator Loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW-UXoEdIeXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McIPUozXJlDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JExFlcK7K9Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CJAlmuZLTur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt\")\n",
        "tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                    discriminator_optimizer=discriminator_optimizer,\n",
        "                    generator=generator,\n",
        "                    discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJJXKW_GMTV0",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzZyM2gJMQSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJq_FHhMvJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training = True)\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKhZHLHOPpeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, \n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "    \n",
        "    #Save the model every 15 epochs\n",
        "    if(epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    \n",
        "    print('Time of epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    #Generate after final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch,\n",
        "                             seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU789h-QQ4uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model,epoch,test_input):\n",
        "  # Notice training is set to False\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "\n",
        "  predictions = model(test_input, training = False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(predictions[i, :, :, 0]*127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  \n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esr3ThmaTdBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icno2ieZTtMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MqeonFfk2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE3oC8uLfl_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import savez_compressed\n",
        " \n",
        "# load all images in a directory into memory\n",
        "def load_images(path, size=(256,512)):\n",
        "  src_list, tar_list = list(), list()\n",
        "\t# enumerate filenames in directory, assume all are images\n",
        "  for filename in listdir(path):\n",
        "    pixels = load_img(path + filename, target_size=size)\n",
        "    pixels = img_to_array(pixels)\n",
        "    sat_img, map_img = pixels[:, :256], pixels[:, 256:]\n",
        "    src_list.append(sat_img)\n",
        "    tar_list.append(map_img)\n",
        "  return [asarray(src_list), asarray(tar_list)]\n",
        " \n",
        "# dataset path\n",
        "path = 'garfield/'\n",
        "# load dataset\n",
        "[src_images, tar_images] = load_images(path)\n",
        "print('Loaded: ', src_images.shape, tar_images.shape)\n",
        "# save as compressed numpy array\n",
        "filename = 'maps_256.npz'\n",
        "savez_compressed(filename, src_images, tar_images)\n",
        "print('Saved dataset: ', filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecp33Oi7wUlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qktTjvjbu0Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}